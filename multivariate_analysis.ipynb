{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfde6d0-beda-423a-95ad-5a2756ed2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from itertools import combinations\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "import shap\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from optbinning import OptimalBinning\n",
    "import utils as ut\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f90059-5b11-4a4f-826d-e0803f23ea1d",
   "metadata": {},
   "source": [
    "### A. Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d43bee6-aef3-4bb4-8c5d-16e00703a970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>account_balance_woe</th>\n",
       "      <th>duration_of_credit_month_woe</th>\n",
       "      <th>sex_marital_status_woe</th>\n",
       "      <th>type_of_apartment_woe</th>\n",
       "      <th>payment_status_of_previous_credit_woe</th>\n",
       "      <th>purpose_woe</th>\n",
       "      <th>credit_amount_woe</th>\n",
       "      <th>value_savings_stocks_woe</th>\n",
       "      <th>length_of_current_employment_woe</th>\n",
       "      <th>most_valuable_available_asset_woe</th>\n",
       "      <th>age_years_woe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.818099</td>\n",
       "      <td>0.096228</td>\n",
       "      <td>0.235341</td>\n",
       "      <td>0.404445</td>\n",
       "      <td>-0.733741</td>\n",
       "      <td>0.099235</td>\n",
       "      <td>-0.2127</td>\n",
       "      <td>0.271358</td>\n",
       "      <td>0.431137</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>0.528844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.818099</td>\n",
       "      <td>-0.553595</td>\n",
       "      <td>-0.165548</td>\n",
       "      <td>0.404445</td>\n",
       "      <td>-0.733741</td>\n",
       "      <td>0.353105</td>\n",
       "      <td>-0.2127</td>\n",
       "      <td>0.271358</td>\n",
       "      <td>0.032103</td>\n",
       "      <td>-0.461035</td>\n",
       "      <td>-0.314115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.401392</td>\n",
       "      <td>-0.267315</td>\n",
       "      <td>0.235341</td>\n",
       "      <td>0.404445</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>-0.2127</td>\n",
       "      <td>0.139552</td>\n",
       "      <td>-0.298717</td>\n",
       "      <td>-0.461035</td>\n",
       "      <td>0.528844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.818099</td>\n",
       "      <td>-0.267315</td>\n",
       "      <td>-0.165548</td>\n",
       "      <td>0.404445</td>\n",
       "      <td>-0.733741</td>\n",
       "      <td>0.353105</td>\n",
       "      <td>-0.2127</td>\n",
       "      <td>0.271358</td>\n",
       "      <td>0.032103</td>\n",
       "      <td>-0.461035</td>\n",
       "      <td>-0.314115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.818099</td>\n",
       "      <td>-0.267315</td>\n",
       "      <td>-0.165548</td>\n",
       "      <td>-0.196052</td>\n",
       "      <td>-0.733741</td>\n",
       "      <td>0.353105</td>\n",
       "      <td>-0.2127</td>\n",
       "      <td>0.271358</td>\n",
       "      <td>0.032103</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>-0.314115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  year  account_balance_woe  duration_of_credit_month_woe  \\\n",
       "0       1  2016             0.818099                      0.096228   \n",
       "1       1  2018             0.818099                     -0.553595   \n",
       "2       1  2018             0.401392                     -0.267315   \n",
       "3       1  2017             0.818099                     -0.267315   \n",
       "4       1  2019             0.818099                     -0.267315   \n",
       "\n",
       "   sex_marital_status_woe  type_of_apartment_woe  \\\n",
       "0                0.235341               0.404445   \n",
       "1               -0.165548               0.404445   \n",
       "2                0.235341               0.404445   \n",
       "3               -0.165548               0.404445   \n",
       "4               -0.165548              -0.196052   \n",
       "\n",
       "   payment_status_of_previous_credit_woe  purpose_woe  credit_amount_woe  \\\n",
       "0                              -0.733741     0.099235            -0.2127   \n",
       "1                              -0.733741     0.353105            -0.2127   \n",
       "2                               0.088319     0.230524            -0.2127   \n",
       "3                              -0.733741     0.353105            -0.2127   \n",
       "4                              -0.733741     0.353105            -0.2127   \n",
       "\n",
       "   value_savings_stocks_woe  length_of_current_employment_woe  \\\n",
       "0                  0.271358                          0.431137   \n",
       "1                  0.271358                          0.032103   \n",
       "2                  0.139552                         -0.298717   \n",
       "3                  0.271358                          0.032103   \n",
       "4                  0.271358                          0.032103   \n",
       "\n",
       "   most_valuable_available_asset_woe  age_years_woe  \n",
       "0                           0.028573       0.528844  \n",
       "1                          -0.461035      -0.314115  \n",
       "2                          -0.461035       0.528844  \n",
       "3                          -0.461035      -0.314115  \n",
       "4                           0.028573      -0.314115  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "data = pd.read_csv('prepared_dataset.csv')\n",
    "\n",
    "# Fix formats\n",
    "for col in data.columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabae10-0540-4a9c-b809-6af4b057aff3",
   "metadata": {},
   "source": [
    "### B. Create all possible models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d47297-d391-4ee6-a58d-8aa047dfe03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables and generate the combinations of variables\n",
    "num_vars = 5\n",
    "all_vars = [var for var in data.columns if var.endswith('woe')]\n",
    "\n",
    "# Create all combinations\n",
    "model_vars = []\n",
    "\n",
    "for combo in combinations(all_vars, num_vars):\n",
    "    model_vars.append(list(combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a2871-d5d2-4df0-b731-603117a67ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                   | 410/462 [03:44<00:27,  1.88it/s]"
     ]
    }
   ],
   "source": [
    "def create_model(id, data, target, model_vars):\n",
    "    # Create formula, fit the model and predict values\n",
    "    formula = f'{target} ~ ' + ' + '.join(model_vars)\n",
    "    model = smf.logit(formula=formula, data=data).fit(disp=0)   \n",
    "    y_pred = model.predict()\n",
    "\n",
    "    # Create pooling\n",
    "    data['score'] = y_pred\n",
    "    optb = OptimalBinning(name='score', dtype=\"numerical\", solver=\"cp\")\n",
    "    optb.fit(data['score'], data['target'])\n",
    "    data['bin'] = optb.transform(data['score'], metric=\"indices\")\n",
    "\n",
    "    # Create calibration\n",
    "    calibration_df = data.groupby(['bin']).agg({'target': ['mean', 'count']})\n",
    "    calibration_df = calibration_df.reset_index()\n",
    "    calibration_df.columns = ['bin', 'pd', 'pd_count']\n",
    "    data = data.merge(calibration_df, on='bin', how='left')\n",
    "\n",
    "    # Create model stats\n",
    "    gini_coeff = ut.calculate_gini(data['target'], y_pred)\n",
    "    p_values = model.pvalues.drop('Intercept', errors='ignore')\n",
    "    max_p_value = p_values.max()\n",
    "    corr_matrix = data[model_vars].corr()\n",
    "    max_corr = corr_matrix[corr_matrix != 1].stack().abs().max()\n",
    "\n",
    "    # Calculate RWA\n",
    "    asset_class = \"Other Retail Exposures\"\n",
    "    data['rwa'] = data['pd'].apply(lambda x: ut.calculate_RWA(asset_class, x, 0.35, 100, 1.06))\n",
    "    rwa_df = data.groupby(['year']).agg({'rwa': ['sum']})\n",
    "    rwa_df.columns = ['agg_sum']\n",
    "\n",
    "    # Perform permutation importance\n",
    "    imp = ut.calculate_most_important_feature(data, 'target', model_vars)\n",
    "    \n",
    "    # Determine if pools are monotically increasing\n",
    "    calibration_df = calibration_df.sort_values(by='bin')\n",
    "    is_monotonic_increasing = calibration_df['pd'].is_monotonic_increasing\n",
    "\n",
    "    # Calculate HHI of the last period and PSI for AP vs non-API\n",
    "    hhi = ut.calculate_hhi(calibration_df, 'pd_count')\n",
    "    psi = ut.calculate_psi(data, 'year', 'bin')\n",
    "\n",
    "    # Create dictionary to return\n",
    "    return {\n",
    "        \"model_id\": id,\n",
    "        \"model_gini\": gini_coeff,\n",
    "        \"psi_ap_vs_non_api\": psi,\n",
    "        \"monotonic_bins\": is_monotonic_increasing,\n",
    "        \"HHI_bins_application_portfolio\": hhi,\n",
    "        \"max_p_value\": max_p_value,\n",
    "        \"max_correlation\": max_corr,\n",
    "        \"max_var_importance\": imp[1],\n",
    "        \"max_div_min_rwa\": rwa_df['agg_sum'].max() / rwa_df['agg_sum'].min(),        \n",
    "        \"num_of_predictors\": len(model_vars),\n",
    "    }\n",
    "\n",
    "# Create a dataset with stats covering all models\n",
    "models = []\n",
    "for i, risk_drivers in enumerate(tqdm(model_vars)):\n",
    "    res_model = create_model(i, data, 'target', risk_drivers)\n",
    "    models.append(res_model)\n",
    "\n",
    "all_models = pd.DataFrame(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9750a2-d244-495c-be1f-c4575a0951ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3cc33-566f-4ee5-ac73-f916f48b06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying style for formatting numerical columns\n",
    "styled_df = all_models.sort_values(by='model_gini', ascending=False).head().style.format({\n",
    "    \"model_gini\": \"{:.2%}\",\n",
    "    \"psi_ap_vs_non_api\": \"{:.2%}\",\n",
    "    \"HHI_bins_application_portfolio\": \"{:.2%}\",\n",
    "    \"max_p_value\": \"{:.2%}\",\n",
    "    \"max_correlation\": \"{:.2%}\",\n",
    "    \"max_var_importance\": \"{:,.2f}%\",\n",
    "    \"max_div_min_rwa\": \"{:,.2%}\",\n",
    "})\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb92b2-7952-4a42-b0ea-21b3c31e4d37",
   "metadata": {},
   "source": [
    "### C. Test other multivariate algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92bf92-0108-4cd7-ba94-0c1f078f9bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def summarise_results(model, data, model_vars):\n",
    "    # Create model stats\n",
    "    gini_coeff = ut.calculate_gini(data['target'], data['score'])\n",
    "    p_values = model.pvalues.drop('Intercept', errors='ignore')\n",
    "    max_p_value = p_values.max()\n",
    "    corr_matrix = data[model_vars].corr()\n",
    "    max_corr = corr_matrix[corr_matrix != 1].stack().abs().max()\n",
    "\n",
    "    print(f'Gini: {gini_coeff:.2%}, max correlation: {max_corr:.2%}, max_p_value: {max_p_value:.2%}, {model_vars}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ddf2f-ffda-439a-ab64-f4ef522565e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://rdrr.io/github/louis-vines/creditr/f/vignettes/using-miv-to-select-variables-in-regression.Rmd\n",
    "model_vars = []\n",
    "potential_vars = [var for var in data.columns if var.endswith('woe')]\n",
    "\n",
    "while True:\n",
    "    all_stats = pd.DataFrame()\n",
    "\n",
    "    # Create formula, fit the model and predict values\n",
    "    if len(model_vars) == 0:\n",
    "        formula = f'target ~ 1'\n",
    "    else:\n",
    "        formula = f'target ~ ' + ' + '.join(model_vars)\n",
    "    \n",
    "    model = smf.logit(formula=formula, data=data).fit(disp=0)   \n",
    "    data['score'] = model.predict()\n",
    "    \n",
    "    for potential_var in potential_vars:\n",
    "        \n",
    "        # Create marginal information value per potential variables\n",
    "        stats = ut.observed_expected_woe(data, potential_var, 'target', 'score')\n",
    "        all_stats = pd.concat([all_stats, stats])\n",
    "\n",
    "    # Pick the best feature above a threshold from all MIVs per feature\n",
    "    mivs = all_stats.groupby('feature').agg({'miv': 'max', 'p_val': 'max'}).reset_index()\n",
    "    p_value_threshold = 0.05\n",
    "    filtered_df = mivs[mivs['p_val'] < p_value_threshold]\n",
    "\n",
    "    if len(filtered_df) == 0:\n",
    "        break\n",
    "    else:\n",
    "        best_feature = filtered_df.loc[filtered_df['miv'].idxmax()]['feature']\n",
    "        \n",
    "    model_vars.append(best_feature)\n",
    "    potential_vars.remove(best_feature)\n",
    "\n",
    "    # Create a summary\n",
    "    formula = f'target ~ ' + ' + '.join(model_vars)\n",
    "    model = smf.logit(formula=formula, data=data).fit(disp=0)   \n",
    "    data['score'] = model.predict()\n",
    "    summarise_results(model, data, model_vars)\n",
    "    \n",
    "    if (len(potential_vars) == 0) | (len(model_vars) == 5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa283ee-6bb9-404b-ae0f-8ca1bf2aa8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_lasso(df, target_column, n_features, n_alphas=100, random_state=0):\n",
    "    # Separate features and target variable\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Generate a list of alphas\n",
    "    alpha_max = np.max(np.abs(X.T.dot(y))) / X.shape[0]  # Rough estimate of the upper bound\n",
    "    alphas = np.logspace(-4, np.log10(alpha_max), n_alphas)\n",
    "\n",
    "    closest_alpha = None\n",
    "    closest_feature_count = np.inf\n",
    "\n",
    "    # Iterate through alphas to find the one closest to desired number of features\n",
    "    for alpha in alphas:\n",
    "        lasso = Lasso(alpha=alpha, random_state=random_state)\n",
    "        lasso.fit(X, y)\n",
    "        nonzero_features = np.sum(lasso.coef_ != 0)\n",
    "\n",
    "        # Check if this alpha gives a closer feature count to our target\n",
    "        if abs(nonzero_features - n_features) < abs(closest_feature_count - n_features):\n",
    "            closest_alpha = alpha\n",
    "            closest_feature_count = nonzero_features\n",
    "\n",
    "        # Stop if we reach the desired number of features\n",
    "        if nonzero_features == n_features:\n",
    "            break\n",
    "\n",
    "    # Fit the final model with the determined alpha\n",
    "    final_lasso = Lasso(alpha=closest_alpha, random_state=random_state)\n",
    "    final_lasso.fit(X, y)\n",
    "\n",
    "    # Extracting feature names\n",
    "    feature_names = X.columns[final_lasso.coef_ != 0].tolist()\n",
    "    \n",
    "    return feature_names\n",
    "\n",
    "# Create a model with Lasso\n",
    "target_column = 'target'\n",
    "potential_vars = [var for var in data.columns if var.endswith('woe')]\n",
    "feature_names = mv_lasso(data[[target_column] + potential_vars], target_column, n_features=5)\n",
    "\n",
    "# Create a summary\n",
    "formula = f'target ~ ' + ' + '.join(feature_names)\n",
    "model = smf.logit(formula=formula, data=data).fit(disp=0)   \n",
    "data['score'] = model.predict()\n",
    "summarise_results(model, data, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4dce41-8888-45bc-a56d-15d7980909a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_stepwise(df, target_column, max_features, threshold_in=0.01, threshold_out=0.05, verbose=False):\n",
    "\n",
    "    X = df.drop(columns=[target_column])  # Separate the features\n",
    "    included = []\n",
    "    while True:\n",
    "        changed = False\n",
    "        # forward step\n",
    "        if len(included) < max_features:\n",
    "            excluded = list(set(X.columns) - set(included))\n",
    "            new_pval = pd.Series(index=excluded)\n",
    "            for new_column in excluded:\n",
    "                formula = \"{} ~ {}\".format(target_column, ' + '.join(included + [new_column]))\n",
    "                model = smf.logit(formula, data=df).fit(disp=0)\n",
    "                new_pval[new_column] = model.pvalues[new_column]\n",
    "            best_pval = new_pval.min()\n",
    "            if best_pval < threshold_in:\n",
    "                best_feature = new_pval.idxmin()\n",
    "                included.append(best_feature)\n",
    "                changed = True\n",
    "                if verbose:\n",
    "                    print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        if len(included) > 0:\n",
    "            formula = \"{} ~ {}\".format(target_column, ' + '.join(included))\n",
    "            model = smf.logit(formula, data=df).fit(disp=0)\n",
    "            pvalues = model.pvalues.iloc[1:]  # exclude intercept\n",
    "            worst_pval = pvalues.max()  # null if pvalues is empty\n",
    "            if worst_pval > threshold_out:\n",
    "                changed = True\n",
    "                worst_feature = pvalues.idxmax()\n",
    "                included.remove(worst_feature)\n",
    "                if verbose:\n",
    "                    print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "# Create a model with Lasso\n",
    "target_column = 'target'\n",
    "potential_vars = [var for var in data.columns if var.endswith('woe')]\n",
    "feature_names = mv_stepwise(data[[target_column] + potential_vars], target_column, 5)\n",
    "\n",
    "# Create a summary\n",
    "formula = f'target ~ ' + ' + '.join(feature_names)\n",
    "model = smf.logit(formula=formula, data=data).fit(disp=0)   \n",
    "data['score'] = model.predict()\n",
    "summarise_results(model, data, feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
